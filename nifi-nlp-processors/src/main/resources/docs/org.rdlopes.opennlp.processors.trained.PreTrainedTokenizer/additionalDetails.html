<!DOCTYPE html>
<html lang="en">

<head>
    <meta charset="utf-8"/>
    <title>PreTrainedTokenizer</title>
    <link href="/nifi-docs/css/component-usage.css" rel="stylesheet" type="text/css"/>
</head>

<body>

<h2>PreTrainedTokenizer</h2>
<ul>
    <li><a href="#evaluation">Evaluation</a></li>
    <li><a href="#output">Output</a></li>
</ul>
<img alt="Tokenizer flow" src="../org.rdlopes.opennlp.processors.trainable.TrainableTokenizer/tokenizer-flow.png">
<p>This processor wraps the evaluation from <a href="https://opennlp.apache.org/docs/1.9.1/manual/opennlp.html#tools.tokenizer">OpenNLP Tokenizer</a>.
    The OpenNLP Tokenizer segment an input character sequence into tokens.
    Tokens are usually words, punctuation, numbers, etc.
    It loads its model from a file path.</p>
<p>This processor implements the following tokenizers:
<ul>
    <li>Learnable Tokenizer - A maximum entropy tokenizer, detects token boundaries based on probability model</li>
</ul>
<p>Most part-of-speech taggers, parsers and so on, work with text tokenized in this manner.
    It is important to ensure that your tokenizer produces tokens of the type expected by your later text processing components.</p>

<h3 id="evaluation">Evaluation</h3>
<p>PreTrainedTokenizer runs against full text, meaning it will read the flow file content.</p>

<h3 id="output">Output</h3>
<p>PreTrainedTokenizer will enrich flow file attributes with</p>
<ul>
    <li><strong>nlp.tokenizer.tokens.list</strong>: the tokens list</li>
    <li><strong>nlp.tokenizer.tokens.span</strong>: the token spans</li>
</ul>

</body>
</html>
